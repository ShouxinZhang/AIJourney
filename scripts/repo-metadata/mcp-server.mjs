#!/usr/bin/env node
/**
 * repo-metadata MCP Server
 *
 * æä¾›ä»“åº“å…ƒæ•°æ® CRUDã€æ‰«æã€ç”Ÿæˆæ¶æ„æ–‡æ¡£ã€PG åŒæ­¥ç­‰ MCP Toolsï¼Œ
 * ä¾› LLM ç›´æ¥è°ƒç”¨ï¼Œæ— éœ€æ‹¼ç»ˆç«¯å‘½ä»¤ã€‚
 *
 * ä¼ è¾“æ–¹å¼: stdioï¼ˆVS Code Copilot æ ‡å‡†é›†æˆï¼‰
 */
import { execSync } from 'node:child_process';
import fs from 'node:fs/promises';
import path from 'node:path';
import { fileURLToPath } from 'node:url';

import { McpServer } from '@modelcontextprotocol/sdk/server/mcp.js';
import { StdioServerTransport } from '@modelcontextprotocol/sdk/server/stdio.js';
import { z } from 'zod';

/* ------------------------------------------------------------------ */
/*  è·¯å¾„å¸¸é‡                                                           */
/* ------------------------------------------------------------------ */

const scriptDir = path.dirname(fileURLToPath(import.meta.url));
const repoRoot = path.resolve(scriptDir, '../../');
const metadataPath = path.join(repoRoot, 'docs', 'architecture', 'repo-metadata.json');
const structureMdPath = path.join(repoRoot, 'docs', 'architecture', 'repository-structure.md');

const MARKER_START = '<!-- REPO-TREE-START -->';
const MARKER_END = '<!-- REPO-TREE-END -->';

/* ------------------------------------------------------------------ */
/*  å…ƒæ•°æ® JSON è¯»å†™                                                    */
/* ------------------------------------------------------------------ */

async function loadMetadata() {
  try {
    const content = await fs.readFile(metadataPath, 'utf8');
    return JSON.parse(content);
  } catch {
    return {
      version: 1,
      config: {
        scanIgnore: ['docs/dev_logs/**', 'docs/knowledge/_archive/**'],
        generateMdDepth: 2,
      },
      updatedAt: new Date().toISOString(),
      nodes: {},
    };
  }
}

async function saveMetadata(metadata) {
  metadata.updatedAt = new Date().toISOString();
  const sorted = Object.keys(metadata.nodes).sort();
  const orderedNodes = {};
  for (const key of sorted) {
    orderedNodes[key] = metadata.nodes[key];
  }
  metadata.nodes = orderedNodes;
  await fs.mkdir(path.dirname(metadataPath), { recursive: true });
  await fs.writeFile(metadataPath, `${JSON.stringify(metadata, null, 2)}\n`, 'utf8');
}

/* ------------------------------------------------------------------ */
/*  Scan æ ¸å¿ƒé€»è¾‘                                                      */
/* ------------------------------------------------------------------ */

function globToRegex(pattern) {
  const re = pattern
    .replace(/[.+^${}()|[\]\\]/g, '\\$&')
    .replace(/\*\*/g, '{{GLOBSTAR}}')
    .replace(/\*/g, '[^/]*')
    .replace(/\?/g, '[^/]')
    .replace(/\{\{GLOBSTAR\}\}/g, '.*');
  return new RegExp(`^${re}$`);
}

function getTrackedPaths() {
  const output = execSync('git ls-files', { cwd: repoRoot, encoding: 'utf8' });
  const files = output.trim().split('\n').filter(Boolean);
  const fileSet = new Set(files);
  const dirSet = new Set();
  for (const file of files) {
    let dir = path.dirname(file);
    while (dir !== '.') {
      if (dirSet.has(dir)) break;
      dirSet.add(dir);
      dir = path.dirname(dir);
    }
  }
  return { fileSet, dirSet };
}

function shouldIgnore(p, matchers) {
  return matchers.some((re) => re.test(p));
}

function depthOf(p) {
  return p.split('/').length;
}

/* ------------------------------------------------------------------ */
/*  Tree / MD ç”Ÿæˆé€»è¾‘                                                  */
/* ------------------------------------------------------------------ */

function buildTree(nodes) {
  const root = { name: 'AIJourney', children: new Map(), meta: null };
  for (const [nodePath, meta] of Object.entries(nodes)) {
    const parts = nodePath.split('/');
    let current = root;
    for (const part of parts) {
      if (!current.children.has(part)) {
        current.children.set(part, { name: part, children: new Map(), meta: null });
      }
      current = current.children.get(part);
    }
    current.meta = meta;
  }
  return root;
}

function renderTree(root, maxDepth) {
  const lines = [`${root.name}/`];
  function renderChildren(node, prefix, currentDepth) {
    if (currentDepth >= maxDepth) return;
    const entries = [...node.children.entries()].sort(([aName, aNode], [bName, bNode]) => {
      const aIsDir = aNode.meta?.type === 'directory' || aNode.children.size > 0;
      const bIsDir = bNode.meta?.type === 'directory' || bNode.children.size > 0;
      if (aIsDir !== bIsDir) return aIsDir ? -1 : 1;
      return aName.localeCompare(bName);
    });
    entries.forEach(([name, child], index) => {
      const isLast = index === entries.length - 1;
      const connector = isLast ? 'â””â”€â”€ ' : 'â”œâ”€â”€ ';
      const isDir = child.meta?.type === 'directory' || child.children.size > 0;
      const displayName = isDir ? `${name}/` : name;
      const desc = child.meta?.description || '';
      const nameWidth = prefix.length + connector.length + displayName.length;
      const PAD_TO = 45;
      const padding = desc ? ' '.repeat(Math.max(1, PAD_TO - nameWidth)) : '';
      const comment = desc ? `${padding}# ${desc}` : '';
      lines.push(`${prefix}${connector}${displayName}${comment}`);
      if (isDir && currentDepth + 1 < maxDepth) {
        const childPrefix = prefix + (isLast ? '    ' : 'â”‚   ');
        renderChildren(child, childPrefix, currentDepth + 1);
      }
    });
  }
  renderChildren(root, '', 0);
  return lines.join('\n');
}

async function updateStructureMd(treeContent) {
  let md;
  try {
    md = await fs.readFile(structureMdPath, 'utf8');
  } catch {
    md = `# AI Journey - ä»“åº“æ¶æ„æ–‡æ¡£\n\n## ç›®å½•ç»“æ„\n\n${MARKER_START}\n\`\`\`\n\`\`\`\n${MARKER_END}\n`;
  }
  const startIdx = md.indexOf(MARKER_START);
  const endIdx = md.indexOf(MARKER_END);
  const treeBlock = `${MARKER_START}\n\`\`\`\n${treeContent}\n\`\`\`\n${MARKER_END}`;
  if (startIdx !== -1 && endIdx !== -1) {
    md = md.slice(0, startIdx) + treeBlock + md.slice(endIdx + MARKER_END.length);
  } else {
    const sectionMatch = md.match(/## ç›®å½•ç»“æ„\s*\n/);
    if (sectionMatch) {
      const sectionStart = sectionMatch.index + sectionMatch[0].length;
      const codeBlockMatch = md.slice(sectionStart).match(/```[\s\S]*?```/);
      if (codeBlockMatch) {
        const blockStart = sectionStart + codeBlockMatch.index;
        const blockEnd = blockStart + codeBlockMatch[0].length;
        md = md.slice(0, blockStart) + treeBlock + md.slice(blockEnd);
      } else {
        md = md.slice(0, sectionStart) + '\n' + treeBlock + '\n' + md.slice(sectionStart);
      }
    } else {
      md += `\n## ç›®å½•ç»“æ„\n\n${treeBlock}\n`;
    }
  }
  await fs.writeFile(structureMdPath, md, 'utf8');
}

/* ------------------------------------------------------------------ */
/*  PG åŒæ­¥è¾…åŠ©ï¼ˆåŠ¨æ€ import pgï¼Œä»…åœ¨éœ€è¦æ—¶ï¼‰                          */
/* ------------------------------------------------------------------ */

async function getPgClient() {
  const databaseUrl = process.env.DATABASE_URL;
  if (!databaseUrl) {
    throw new Error('ç¼ºå°‘ DATABASE_URL ç¯å¢ƒå˜é‡ï¼Œæ— æ³•æ‰§è¡Œ PG åŒæ­¥ã€‚');
  }
  const { Client } = await import('pg');
  const client = new Client({ connectionString: databaseUrl });
  await client.connect();
  return client;
}

/* ------------------------------------------------------------------ */
/*  MCP Server å®šä¹‰                                                    */
/* ------------------------------------------------------------------ */

const server = new McpServer({
  name: 'repo-metadata',
  version: '1.0.0',
});

// â”€â”€â”€ Tool 1: scan â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

server.tool(
  'repo_metadata_scan',
  'æ‰«æä»“åº“ç›®å½•ç»“æ„ï¼Œå¯¹æ¯” repo-metadata.jsonï¼ŒæŠ¥å‘Šæ–°å¢/åˆ é™¤/æœªæè¿°çš„æ¡ç›®ã€‚å¯é€‰è‡ªåŠ¨æ›´æ–° JSONã€‚',
  {
    update: z.boolean().optional().default(false).describe('æ˜¯å¦è‡ªåŠ¨æ›´æ–° repo-metadata.json'),
    maxDepth: z.number().optional().describe('æœ€å¤§æ‰«ææ·±åº¦ï¼ˆé»˜è®¤: æ— é™åˆ¶ï¼‰'),
  },
  async ({ update, maxDepth }) => {
    const { fileSet, dirSet } = getTrackedPaths();
    const metadata = await loadMetadata();
    const ignoreMatchers = (metadata.config?.scanIgnore ?? []).map(globToRegex);

    const diskPaths = new Map();
    for (const d of dirSet) {
      if (!shouldIgnore(d, ignoreMatchers)) diskPaths.set(d, 'directory');
    }
    for (const f of fileSet) {
      if (!shouldIgnore(f, ignoreMatchers)) diskPaths.set(f, 'file');
    }

    const filteredPaths = maxDepth
      ? new Map([...diskPaths].filter(([p]) => depthOf(p) <= maxDepth))
      : diskPaths;

    const existingPaths = new Set(Object.keys(metadata.nodes));
    const added = [];
    const undescribed = [];

    for (const [p, type] of filteredPaths) {
      if (!existingPaths.has(p)) {
        added.push({ path: p, type });
      } else if (!metadata.nodes[p].description) {
        undescribed.push(p);
      }
    }

    const removed = [];
    for (const p of existingPaths) {
      if (!filteredPaths.has(p)) removed.push(p);
    }

    if (update) {
      const now = new Date().toISOString();
      for (const { path: p, type } of added) {
        metadata.nodes[p] = {
          type,
          description: '',
          detail: '',
          tags: [],
          updatedBy: 'scan',
          updatedAt: now,
        };
      }
      for (const p of removed) {
        delete metadata.nodes[p];
      }
      await saveMetadata(metadata);
    }

    const lines = [];
    lines.push(`æ‰«æå®Œæˆ: ${filteredPaths.size} ä¸ªè·¯å¾„`);
    if (added.length > 0) {
      lines.push(`\nğŸ†• æ–°å¢ (${added.length}):`);
      for (const { path: p, type } of added.sort((a, b) => a.path.localeCompare(b.path))) {
        lines.push(`  + ${p}  (${type})`);
      }
    }
    if (removed.length > 0) {
      lines.push(`\nğŸ—‘ï¸ å·²åˆ é™¤ (${removed.length}):`);
      for (const p of removed.sort()) lines.push(`  - ${p}`);
    }
    if (undescribed.length > 0) {
      lines.push(`\nâš ï¸ æœªæè¿° (${undescribed.length}):`);
      for (const p of undescribed.sort()) lines.push(`  ? ${p}`);
    }
    if (added.length === 0 && removed.length === 0 && undescribed.length === 0) {
      lines.push('\nâœ… å…ƒæ•°æ®ä¸æ–‡ä»¶ç³»ç»Ÿå®Œå…¨åŒæ­¥ï¼Œæ‰€æœ‰æ¡ç›®å·²æè¿°ã€‚');
    }
    if (update) {
      lines.push(`\nâœ… å·²æ›´æ–° repo-metadata.json: ${added.length} added, ${removed.length} removed`);
    }

    return { content: [{ type: 'text', text: lines.join('\n') }] };
  },
);

// â”€â”€â”€ Tool 2: get â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

server.tool(
  'repo_metadata_get',
  'è·å–æŒ‡å®šè·¯å¾„çš„å…ƒæ•°æ®è¯¦æƒ…ï¼ˆæè¿°ã€æ ‡ç­¾ã€ç±»å‹ç­‰ï¼‰ã€‚',
  {
    path: z.string().describe('ç›¸å¯¹è·¯å¾„ï¼Œå¦‚ "web/src/components"'),
  },
  async ({ path: nodePath }) => {
    const metadata = await loadMetadata();
    const node = metadata.nodes[nodePath];
    if (!node) {
      return { content: [{ type: 'text', text: `âŒ è·¯å¾„ä¸å­˜åœ¨: ${nodePath}` }] };
    }
    return {
      content: [{ type: 'text', text: JSON.stringify({ path: nodePath, ...node }, null, 2) }],
    };
  },
);

// â”€â”€â”€ Tool 3: set â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

server.tool(
  'repo_metadata_set',
  'è®¾ç½®/æ›´æ–°æŒ‡å®šè·¯å¾„çš„å…ƒæ•°æ®ï¼ˆæè¿°ã€æ ‡ç­¾ç­‰ï¼‰ã€‚è·¯å¾„ä¸å­˜åœ¨æ—¶è‡ªåŠ¨åˆ›å»ºã€‚',
  {
    path: z.string().describe('ç›¸å¯¹è·¯å¾„'),
    description: z.string().optional().describe('ä¸€å¥è¯æè¿°'),
    detail: z.string().optional().describe('è¯¦ç»†è¯´æ˜'),
    tags: z.array(z.string()).optional().describe('æ ‡ç­¾æ•°ç»„'),
    type: z.enum(['file', 'directory']).optional().describe('ç±»å‹'),
  },
  async ({ path: nodePath, description, detail, tags, type }) => {
    const metadata = await loadMetadata();
    const now = new Date().toISOString();
    const existing = metadata.nodes[nodePath] ?? {
      type: type ?? 'directory',
      description: '',
      detail: '',
      tags: [],
      updatedBy: 'llm',
      updatedAt: now,
    };

    if (description !== undefined) existing.description = description;
    if (detail !== undefined) existing.detail = detail;
    if (tags !== undefined) existing.tags = tags;
    if (type !== undefined) existing.type = type;
    existing.updatedBy = 'llm';
    existing.updatedAt = now;

    metadata.nodes[nodePath] = existing;
    await saveMetadata(metadata);

    return { content: [{ type: 'text', text: `âœ… å·²æ›´æ–°: ${nodePath}` }] };
  },
);

// â”€â”€â”€ Tool 4: batch_set â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

server.tool(
  'repo_metadata_batch_set',
  'æ‰¹é‡è®¾ç½®å¤šæ¡è·¯å¾„çš„æè¿°ä¿¡æ¯ã€‚é€‚åˆ LLM ä¸€æ¬¡æ€§è¡¥å†™å¤šä¸ªæ–°å¢æ¡ç›®ã€‚',
  {
    items: z
      .array(
        z.object({
          path: z.string().describe('ç›¸å¯¹è·¯å¾„'),
          description: z.string().optional().describe('ä¸€å¥è¯æè¿°'),
          detail: z.string().optional().describe('è¯¦ç»†è¯´æ˜'),
          tags: z.array(z.string()).optional().describe('æ ‡ç­¾æ•°ç»„'),
        }),
      )
      .describe('è¦æ›´æ–°çš„æ¡ç›®æ•°ç»„'),
  },
  async ({ items }) => {
    const metadata = await loadMetadata();
    const now = new Date().toISOString();
    let updated = 0;
    let skipped = 0;

    for (const item of items) {
      const existing = metadata.nodes[item.path];
      if (!existing) {
        skipped++;
        continue;
      }
      if (item.description !== undefined) existing.description = item.description;
      if (item.detail !== undefined) existing.detail = item.detail;
      if (item.tags !== undefined) existing.tags = item.tags;
      existing.updatedBy = 'llm';
      existing.updatedAt = now;
      metadata.nodes[item.path] = existing;
      updated++;
    }

    await saveMetadata(metadata);
    return {
      content: [{ type: 'text', text: `âœ… æ‰¹é‡æ›´æ–°å®Œæˆ: ${updated}/${items.length} æ¡ (è·³è¿‡ ${skipped})` }],
    };
  },
);

// â”€â”€â”€ Tool 5: list â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

server.tool(
  'repo_metadata_list',
  'åˆ—å‡ºä»“åº“å…ƒæ•°æ®æ¡ç›®ã€‚æ”¯æŒæŒ‰ç±»å‹ã€æ ‡ç­¾ã€æ·±åº¦ã€æ˜¯å¦æœªæè¿°è¿‡æ»¤ã€‚',
  {
    type: z.enum(['file', 'directory']).optional().describe('è¿‡æ»¤ç±»å‹'),
    tag: z.string().optional().describe('è¿‡æ»¤æ ‡ç­¾'),
    maxDepth: z.number().optional().describe('æœ€å¤§æ·±åº¦'),
    undescribedOnly: z.boolean().optional().default(false).describe('åªæ˜¾ç¤ºæœªæè¿°çš„æ¡ç›®'),
  },
  async ({ type, tag, maxDepth, undescribedOnly }) => {
    const metadata = await loadMetadata();
    const entries = Object.entries(metadata.nodes)
      .filter(([p, node]) => {
        if (maxDepth && depthOf(p) > maxDepth) return false;
        if (type && node.type !== type) return false;
        if (tag && !node.tags?.includes(tag)) return false;
        if (undescribedOnly && node.description) return false;
        return true;
      })
      .sort(([a], [b]) => a.localeCompare(b));

    if (entries.length === 0) {
      return { content: [{ type: 'text', text: 'æ²¡æœ‰åŒ¹é…çš„æ¡ç›®ã€‚' }] };
    }

    const lines = entries.map(([p, node]) => {
      const icon = node.type === 'directory' ? 'ğŸ“' : 'ğŸ“„';
      const desc = node.description || '(æœªæè¿°)';
      return `${icon} ${p} â€” ${desc}`;
    });
    lines.push(`\nå…± ${entries.length} æ¡`);

    return { content: [{ type: 'text', text: lines.join('\n') }] };
  },
);

// â”€â”€â”€ Tool 6: delete â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

server.tool(
  'repo_metadata_delete',
  'åˆ é™¤æŒ‡å®šè·¯å¾„çš„å…ƒæ•°æ®æ¡ç›®ï¼ˆçº§è”åˆ é™¤å­è·¯å¾„ï¼‰ã€‚',
  {
    path: z.string().describe('è¦åˆ é™¤çš„ç›¸å¯¹è·¯å¾„'),
  },
  async ({ path: nodePath }) => {
    const metadata = await loadMetadata();
    if (!metadata.nodes[nodePath]) {
      return { content: [{ type: 'text', text: `âŒ è·¯å¾„ä¸å­˜åœ¨: ${nodePath}` }] };
    }

    delete metadata.nodes[nodePath];
    const prefix = `${nodePath}/`;
    let cascaded = 0;
    for (const key of Object.keys(metadata.nodes)) {
      if (key.startsWith(prefix)) {
        delete metadata.nodes[key];
        cascaded++;
      }
    }

    await saveMetadata(metadata);
    return {
      content: [
        { type: 'text', text: `âœ… å·²åˆ é™¤: ${nodePath}${cascaded > 0 ? ` (+ ${cascaded} ä¸ªå­è·¯å¾„)` : ''}` },
      ],
    };
  },
);

// â”€â”€â”€ Tool 7: generate_md â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

server.tool(
  'repo_metadata_generate_md',
  'ä» repo-metadata.json ç”Ÿæˆ/æ›´æ–° repository-structure.md ä¸­çš„ç›®å½•æ ‘ã€‚',
  {
    depth: z.number().optional().describe('ç›®å½•æ ‘å±•å¼€æ·±åº¦ï¼ˆé»˜è®¤: config.generateMdDepth æˆ– 2ï¼‰'),
  },
  async ({ depth }) => {
    const metadata = await loadMetadata();
    const treeDepth = depth ?? metadata.config?.generateMdDepth ?? 2;

    if (Object.keys(metadata.nodes).length === 0) {
      return { content: [{ type: 'text', text: 'âŒ repo-metadata.json ä¸­æ²¡æœ‰èŠ‚ç‚¹æ•°æ®ã€‚' }] };
    }

    const tree = buildTree(metadata.nodes);
    const treeContent = renderTree(tree, treeDepth);
    await updateStructureMd(treeContent);

    const nodeCount = Object.keys(metadata.nodes).length;
    return {
      content: [
        { type: 'text', text: `âœ… å·²æ›´æ–° repository-structure.mdï¼ˆ${nodeCount} ä¸ªèŠ‚ç‚¹ï¼Œå±•å¼€ ${treeDepth} å±‚ï¼‰` },
      ],
    };
  },
);

// â”€â”€â”€ Tool 8: sync_db â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

server.tool(
  'repo_metadata_sync_db',
  'JSON â‡„ PostgreSQL åŒå‘åŒæ­¥ã€‚éœ€è¦ DATABASE_URL ç¯å¢ƒå˜é‡ã€‚',
  {
    direction: z.enum(['json-to-pg', 'pg-to-json']).describe('"json-to-pg" æˆ– "pg-to-json"'),
  },
  async ({ direction }) => {
    const client = await getPgClient();

    try {
      if (direction === 'json-to-pg') {
        const metadata = await loadMetadata();
        const entries = Object.entries(metadata.nodes);

        if (entries.length === 0) {
          return { content: [{ type: 'text', text: 'â„¹ repo-metadata.json ä¸ºç©ºã€‚' }] };
        }

        await client.query('begin');

        const sorted = entries.sort(([a], [b]) => {
          return a.split('/').length - b.split('/').length || a.localeCompare(b);
        });

        let upserted = 0;
        for (const [nodePath, node] of sorted) {
          const parentPath = path.dirname(nodePath);
          await client.query(
            `insert into repo_metadata_nodes (path, type, description, detail, tags, parent_path, sort_order, updated_by)
             values ($1, $2, $3, $4, $5, $6, $7, $8)
             on conflict (path) do update set
               type=excluded.type, description=excluded.description, detail=excluded.detail,
               tags=excluded.tags, parent_path=excluded.parent_path, sort_order=excluded.sort_order,
               updated_by=excluded.updated_by`,
            [
              nodePath,
              node.type,
              node.description || null,
              node.detail || null,
              node.tags ?? [],
              parentPath === '.' ? null : parentPath,
              node.sortOrder ?? 0,
              node.updatedBy ?? 'scan',
            ],
          );
          upserted++;
        }

        const pathSet = new Set(entries.map(([p]) => p));
        const dbRows = await client.query('select path from repo_metadata_nodes');
        let deleted = 0;
        for (const row of dbRows.rows) {
          if (!pathSet.has(row.path)) {
            await client.query('delete from repo_metadata_nodes where path = $1', [row.path]);
            deleted++;
          }
        }

        await client.query('commit');
        return {
          content: [{ type: 'text', text: `âœ… JSON â†’ PG åŒæ­¥å®Œæˆ: upsert ${upserted}, åˆ é™¤ ${deleted}` }],
        };
      } else {
        // pg-to-json
        const result = await client.query(`
          select path, type, description, detail, tags, sort_order, updated_by, updated_at
          from repo_metadata_nodes order by path
        `);

        if (result.rows.length === 0) {
          return { content: [{ type: 'text', text: 'â„¹ PG è¡¨ä¸ºç©ºã€‚' }] };
        }

        const metadata = await loadMetadata();
        const nodes = {};
        for (const row of result.rows) {
          nodes[row.path] = {
            type: row.type,
            description: row.description ?? '',
            detail: row.detail ?? '',
            tags: row.tags ?? [],
            updatedBy: row.updated_by ?? 'scan',
            updatedAt: row.updated_at?.toISOString() ?? new Date().toISOString(),
          };
        }

        metadata.nodes = nodes;
        await saveMetadata(metadata);

        return {
          content: [{ type: 'text', text: `âœ… PG â†’ JSON åŒæ­¥å®Œæˆ: ${result.rows.length} æ¡è®°å½•` }],
        };
      }
    } catch (err) {
      await client.query('rollback').catch(() => {});
      throw err;
    } finally {
      await client.end();
    }
  },
);

/* ------------------------------------------------------------------ */
/*  å¯åŠ¨ Server                                                        */
/* ------------------------------------------------------------------ */

const transport = new StdioServerTransport();
await server.connect(transport);
